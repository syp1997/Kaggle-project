{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from sklearn import preprocessing\n",
    "import zipfile\n",
    "import shutil\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'   \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 427):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthDataSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['sst'])\n",
    "\n",
    "    def __getitem__(self, idx):   \n",
    "        return (self.data['sst'][idx], self.data['t300'][idx], self.data['ua'][idx], self.data['va'][idx]), self.data['label'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_data(data_list, fit=True):\n",
    "    a,b,c,d = data_list[0].shape\n",
    "    all_data = []\n",
    "    for data in data_list:\n",
    "        new_data = data.reshape(-1)\n",
    "        all_data.append(new_data)\n",
    "    all_data = np.stack(all_data,1)\n",
    "    print(all_data.shape)\n",
    "    if fit:\n",
    "        standardScaler.fit(all_data)\n",
    "        print(\"fit train data\")\n",
    "    all_data = standardScaler.transform(all_data)\n",
    "    res_data = []\n",
    "    for i in range(all_data.shape[1]):\n",
    "        data = all_data[:,i].reshape(a,b,c,d)\n",
    "        res_data.append(data)\n",
    "    return res_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data():\n",
    "    \n",
    "#     # CMIP data       \n",
    "#     cmip_sst = torch.load(\"cmip_sst_data.pt\")  ## 56156, 12, 24, 72\n",
    "#     cmip_t300 = torch.load(\"cmip_t300_data.pt\")\n",
    "#     cmip_ua = torch.load(\"cmip_ua_data.pt\")\n",
    "#     cmip_va = torch.load(\"cmip_va_data.pt\")\n",
    "#     cmip_label = torch.load(\"cmip_label.pt\")\n",
    "\n",
    "#     # SODA data    \n",
    "#     soda_data = xr.open_dataset('tcdata/enso_round1_train_20210201/SODA_train.nc')\n",
    "#     soda_label = xr.open_dataset('tcdata/enso_round1_train_20210201/SODA_label.nc')\n",
    "    \n",
    "#     soda_sst = soda_data['sst'][:, :12].values.astype('float32')  # (100, 12, 24, 72)\n",
    "#     soda_t300 = soda_data['t300'][:, :12].values.astype('float32')\n",
    "#     soda_ua = soda_data['ua'][:, :12].values.astype('float32')\n",
    "#     soda_va = soda_data['va'][:, :12].values.astype('float32')\n",
    "#     soda_label = soda_label['nino'][:, 12:36].values.astype('float32')\n",
    "    \n",
    "#     soda_sst = np.nan_to_num(soda_sst) # trans nan to 0\n",
    "#     soda_t300 = np.nan_to_num(soda_t300)\n",
    "#     soda_ua = np.nan_to_num(soda_ua)\n",
    "#     soda_va = np.nan_to_num(soda_va)\n",
    "\n",
    "#     dict_cmip = {\n",
    "#         'sst':cmip_sst,\n",
    "#         't300':cmip_t300,\n",
    "#         'ua':cmip_ua,\n",
    "#         'va': cmip_va,\n",
    "#         'label': cmip_label}\n",
    "#     dict_soda = {\n",
    "#         'sst':soda_sst,\n",
    "#         't300':soda_t300,\n",
    "#         'ua':soda_ua,\n",
    "#         'va': soda_va,\n",
    "#         'label': soda_label}\n",
    "    \n",
    "#     cmip_dataset = EarthDataSet(dict_cmip)\n",
    "#     soda_dataset = EarthDataSet(dict_soda)\n",
    "    \n",
    "#     train_1, valid_1 = random_split(cmip_dataset, [4545, 100])\n",
    "#     train_2, valid_2 = random_split(soda_dataset, [0, 100])\n",
    "    \n",
    "#     train_dataset = train_1 \n",
    "#     valid_dataset = valid_1\n",
    "#     valid_dataset_2 = valid_2\n",
    "    \n",
    "#     print('Train samples: {}, Valid1 samples: {}, Valid2 samples: {}'.format(len(train_dataset), len(valid_dataset), len(valid_dataset_2)))\n",
    "    \n",
    "#     return train_dataset, valid_dataset, valid_dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed()\n",
    "# standardScaler = StandardScaler()\n",
    "# train_dataset, valid_dataset, valid_dataset_2 = load_data()      \n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "# valid_loader_2 = DataLoader(valid_dataset_2, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coreff(x, y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    c1 = sum((x - x_mean) * (y - y_mean))\n",
    "    c2 = sum((x - x_mean)**2) * sum((y - y_mean)**2)\n",
    "    return c1/np.sqrt(c2)\n",
    "\n",
    "def rmse(preds, y):\n",
    "    r = np.sqrt(sum((preds - y)**2) / preds.shape[0])\n",
    "    return r\n",
    "\n",
    "def eval_score(preds, label):\n",
    "    acskill_socre = 0\n",
    "    rmse_score = 0\n",
    "    a = [1.5]*4 + [2]*7 + [3]*7 + [4]*6\n",
    "    for i in range(24):\n",
    "        r = rmse(preds[:, i], label[:, i], ) # T时刻 (100,)\n",
    "        cor = coreff(preds[:, i], label[:, i], )\n",
    "    \n",
    "        rmse_score += r\n",
    "        acskill_socre += a[i] * np.log(i+1) * cor\n",
    "    print(\"acskill_socre:{}, rmse_score:{}\".format(2/3*acskill_socre, rmse_score))\n",
    "    return 2/3 * acskill_socre - rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, log_interval=20):\n",
    "    best_score = -99\n",
    "    loss_epoch = []\n",
    "    score_epoch = []\n",
    "    score_epoch_2 = []\n",
    "    epoch = -1\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for step, ((sst, t300, ua, va), label) in enumerate(valid_loader):\n",
    "        sst = sst.to(device).float()\n",
    "        t300 = t300.to(device).float()\n",
    "        ua = ua.to(device).float()\n",
    "        va = va.to(device).float()\n",
    "        label = label.to(device).float()\n",
    "        preds = model(sst, t300, ua, va)\n",
    "\n",
    "        y_pred.append(preds.cpu().detach().numpy())\n",
    "        y_true.append(label.cpu().detach().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "    x_month = np.arange(24)\n",
    "    score = eval_score(y_true, y_pred)\n",
    "    best_score = score\n",
    "    \n",
    "    y_true_2, y_pred_2 = [], []\n",
    "    for step, ((sst, t300, ua, va), label) in enumerate(valid_loader_2):\n",
    "        sst = sst.to(device).float()\n",
    "        t300 = t300.to(device).float()\n",
    "        ua = ua.to(device).float()\n",
    "        va = va.to(device).float()\n",
    "        label = label.to(device).float()\n",
    "        preds = model(sst, t300, ua, va)\n",
    "\n",
    "        y_pred_2.append(preds.cpu().detach().numpy())\n",
    "        y_true_2.append(label.cpu().detach().numpy())\n",
    "\n",
    "    y_true_2 = np.concatenate(y_true_2, axis=0)\n",
    "    y_pred_2 = np.concatenate(y_pred_2, axis=0)\n",
    "    x_month = np.arange(24)\n",
    "    score_2 = eval_score(y_true_2, y_pred_2)\n",
    "    print('Epoch: {}, Valid Score: {}, Valid Score 2: {}\\n'.format(epoch+1,score,score_2))    \n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        all_loss = []\n",
    "        for step, ((sst, t300, ua, va), label) in enumerate(train_loader):   \n",
    "            sst = sst.to(device).float()\n",
    "            t300 = t300.to(device).float()\n",
    "            ua = ua.to(device).float()\n",
    "            va = va.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            label = label.to(device).float()\n",
    "            preds = model(sst, t300, ua, va)\n",
    "            loss = loss_fn(preds, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            all_loss.append(loss.item())\n",
    "            if step%log_interval == 0:\n",
    "                print('Step: {}, Train Loss: {}'.format(step, loss))\n",
    "        print('Epoch: {}, Train loss: {}'.format(epoch+1, np.mean(all_loss)))\n",
    "        loss_epoch.append(np.mean(all_loss))\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for step, ((sst, t300, ua, va), label) in enumerate(valid_loader):\n",
    "            sst = sst.to(device).float()\n",
    "            t300 = t300.to(device).float()\n",
    "            ua = ua.to(device).float()\n",
    "            va = va.to(device).float()\n",
    "            label = label.to(device).float()\n",
    "            preds = model(sst, t300, ua, va)\n",
    "\n",
    "            y_pred.append(preds.cpu().detach().numpy())\n",
    "            y_true.append(label.cpu().detach().numpy())\n",
    "\n",
    "        y_true = np.concatenate(y_true, axis=0)\n",
    "        y_pred = np.concatenate(y_pred, axis=0)\n",
    "        x_month = np.arange(24)\n",
    "        score = eval_score(y_true, y_pred)\n",
    "        score_epoch.append(score)\n",
    "        \n",
    "        y_true_2, y_pred_2 = [], []\n",
    "        for step, ((sst, t300, ua, va), label) in enumerate(valid_loader_2):\n",
    "            sst = sst.to(device).float()\n",
    "            t300 = t300.to(device).float()\n",
    "            ua = ua.to(device).float()\n",
    "            va = va.to(device).float()\n",
    "            label = label.to(device).float()\n",
    "            preds = model(sst, t300, ua, va)\n",
    "\n",
    "            y_pred_2.append(preds.cpu().detach().numpy())\n",
    "            y_true_2.append(label.cpu().detach().numpy())\n",
    "\n",
    "        y_true_2 = np.concatenate(y_true_2, axis=0)\n",
    "        y_pred_2 = np.concatenate(y_pred_2, axis=0)\n",
    "        x_month = np.arange(24)\n",
    "        score_2 = eval_score(y_true_2, y_pred_2)\n",
    "        score_epoch_2.append(score_2)\n",
    "        print('Epoch: {}, Valid Score: {}, Valid Score 2: {}\\n'.format(epoch+1,score,score_2))    \n",
    "        \n",
    "        torch.save(model.state_dict(), './models/basemodel_epoch_{}.pt'.format(epoch+1))\n",
    "        if score > best_score:\n",
    "            torch.save(model.state_dict(), './models/basemodel_best.pt')\n",
    "            print('Model saved successfully')\n",
    "            best_score = score\n",
    "            \n",
    "        # figure\n",
    "        plt.figure(figsize = (10,5))\n",
    "        for i in range(10):\n",
    "            plt.subplot(5,5,i+1)\n",
    "            plt.plot(x_month, y_true[i],color='red')\n",
    "            plt.plot(x_month, y_pred[i],color='blue')\n",
    "        j = 0\n",
    "        for i in range(10, 23):\n",
    "            plt.subplot(5,5,i+1)\n",
    "            plt.plot(x_month, y_true_2[j],color='red')\n",
    "            plt.plot(x_month, y_pred_2[j],color='blue')\n",
    "            j += 1\n",
    "        plt.subplot(5,5,24)\n",
    "        plt.plot(np.arange(len(loss_epoch))[:20],loss_epoch[-20:])\n",
    "        plt.subplot(5,5,25)\n",
    "        plt.plot(np.arange(len(score_epoch)),score_epoch)\n",
    "        plt.plot(np.arange(len(score_epoch)),score_epoch_2)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    max_score = max(score_epoch)\n",
    "    max_epoch = score_epoch.index(max_score) + 1\n",
    "    print(\"max score: {} at eopch {}\".format(max_score, max_epoch))\n",
    "    max_score_2 = max(score_epoch_2)\n",
    "    max_epoch_2 = score_epoch_2.index(max_score_2) + 1\n",
    "    print(\"max score 2: {} at eopch {}\".format(max_score_2, max_epoch_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(4,8))) \n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(4,8))) \n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(4,8))) \n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(4,8))) \n",
    "        \n",
    "        self.batch_norm = nn.BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(64)\n",
    "        self.linear = nn.Linear(64, 24)\n",
    "\n",
    "    def forward(self, sst, t300, ua, va):\n",
    "        sst = self.conv1(sst)  # batch * 12 * (24 - 2) * (72 -2)\n",
    "        t300 = self.conv2(t300)\n",
    "        ua = self.conv3(ua)\n",
    "        va = self.conv4(va)\n",
    "\n",
    "        sst = torch.flatten(sst, start_dim=2)  # batch * 12 * 1540\n",
    "        t300 = torch.flatten(t300, start_dim=2)\n",
    "        ua = torch.flatten(ua, start_dim=2)\n",
    "        va = torch.flatten(va, start_dim=2)  \n",
    "        \n",
    "        x = torch.cat([sst, t300, ua, va], dim=-1) # batch * 12 * (1540 * 4)\n",
    "        x = self.batch_norm(x)\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs, 1, -1)\n",
    "        x = self.avgpool(x).squeeze(-2)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(1, 128): max score: 44.37983631523829 at eopch 49; max score 2: 5.373897295704463 at eopch 20\\n(1, 64):  max score: 38.86314433249353 at eopch 48, max score 2: 12.67324381162318 at eopch 50\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "(1, 128): max score: 44.37983631523829 at eopch 49; max score 2: 5.373897295704463 at eopch 20\n",
    "(1, 64):  max score: 38.86314433249353 at eopch 48, max score 2: 12.67324381162318 at eopch 50\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_ids = [i for i in range(int(torch.cuda.device_count()))]\n",
    "    model = torch.nn.DataParallel(model.to(\"cuda:0\"), device_ids=gpu_ids)\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Model : all params: 0.020064M\n"
     ]
    }
   ],
   "source": [
    "print('{} : all params: {:4f}M'.format(model._get_name(), sum(p.numel() for p in model.parameters()) / 1000 / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Model(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(12, 12, kernel_size=(4, 8), stride=(1, 1))\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(12, 12, kernel_size=(4, 8), stride=(1, 1))\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(12, 12, kernel_size=(4, 8), stride=(1, 1))\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(12, 12, kernel_size=(4, 8), stride=(1, 1))\n",
       "  )\n",
       "  (batch_norm): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=64)\n",
       "  (linear): Linear(in_features=64, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('models/basemodel_best.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './tcdata/enso_round1_test_20210201/'\n",
    "\n",
    "### load test data\n",
    "files = os.listdir(test_path)\n",
    "test_feas_dict = {}\n",
    "for file in files:\n",
    "    test_feas_dict[file] = np.load(test_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. predict\n",
    "test_predicts_dict = {}\n",
    "for file_name, val in test_feas_dict.items():\n",
    "    SST = np.expand_dims(val[:,:,:,0],axis=0)\n",
    "    T300 = np.expand_dims(val[:,:,:,1],axis=0)\n",
    "    Ua = np.expand_dims(val[:,:,:,2],axis=0)\n",
    "    Va = np.expand_dims(val[:,:,:,3],axis=0)\n",
    "    \n",
    "    SST = np.nan_to_num(SST) # trans nan to 0\n",
    "    T300 = np.nan_to_num(T300)\n",
    "    Ua = np.nan_to_num(Ua)\n",
    "    Va = np.nan_to_num(Va)\n",
    "    \n",
    "#     data_list = [SST,T300,Ua,Va]\n",
    "#     SST,T300,Ua,Va = fit_data(data_list, fit=False)\n",
    "\n",
    "    SST = torch.tensor(SST).to(device).float()\n",
    "    T300 = torch.tensor(T300).to(device).float()\n",
    "    Ua = torch.tensor(Ua).to(device).float()\n",
    "    Va = torch.tensor(Va).to(device).float()\n",
    "    \n",
    "    result = model(SST, T300, Ua, Va).view(-1).detach().cpu().numpy()\n",
    "    test_predicts_dict[file_name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. save results\n",
    "if os.path.exists('./result/'):  \n",
    "    shutil.rmtree('./result/', ignore_errors=True)  \n",
    "os.makedirs('./result/')\n",
    "for file_name, val in test_predicts_dict.items(): \n",
    "    np.save('./result/' + file_name, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_zip(res_dir='./result', output_dir='result.zip'):  \n",
    "    z = zipfile.ZipFile(output_dir, 'w')  \n",
    "    for file in os.listdir(res_dir):  \n",
    "        if '.npy' not in file:\n",
    "            continue\n",
    "        z.write(res_dir + os.sep + file)  \n",
    "    z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
