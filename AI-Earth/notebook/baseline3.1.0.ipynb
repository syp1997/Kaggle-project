{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import zipfile\n",
    "import shutil\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'   \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 427):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # CMIP data    \n",
    "    train = xr.open_dataset('tcdata/enso_round1_train_20210201/CMIP_train.nc')\n",
    "    label = xr.open_dataset('tcdata/enso_round1_train_20210201/CMIP_label.nc')    \n",
    "   \n",
    "    train_sst = train['sst'][:, :12].values  # (4645, 12, 24, 72)\n",
    "    train_t300 = train['t300'][:, :12].values\n",
    "    train_ua = train['ua'][:, :12].values\n",
    "    train_va = train['va'][:, :12].values\n",
    "    train_label = label['nino'][:, 12:36].values\n",
    "\n",
    "    train_ua = np.nan_to_num(train_ua)\n",
    "    train_va = np.nan_to_num(train_va)\n",
    "    train_t300 = np.nan_to_num(train_t300)\n",
    "    train_sst = np.nan_to_num(train_sst)\n",
    "\n",
    "    # SODA data    \n",
    "    train2 = xr.open_dataset('tcdata/enso_round1_train_20210201/SODA_train.nc')\n",
    "    label2 = xr.open_dataset('tcdata/enso_round1_train_20210201/SODA_label.nc')\n",
    "    \n",
    "    train_sst2 = train2['sst'][:, :12].values  # (100, 12, 24, 72)\n",
    "    train_t3002 = train2['t300'][:, :12].values\n",
    "    train_ua2 = train2['ua'][:, :12].values\n",
    "    train_va2 = train2['va'][:, :12].values\n",
    "    train_label2 = label2['nino'][:, 12:36].values\n",
    "\n",
    "    print('Train samples: {}, Valid samples: {}'.format(len(train_label), len(train_label2)))\n",
    "\n",
    "    dict_train = {\n",
    "        'sst':train_sst,\n",
    "        't300':train_t300,\n",
    "        'ua':train_ua,\n",
    "        'va': train_va,\n",
    "        'label': train_label}\n",
    "    dict_valid = {\n",
    "        'sst':train_sst2,\n",
    "        't300':train_t3002,\n",
    "        'ua':train_ua2,\n",
    "        'va': train_va2,\n",
    "        'label': train_label2}\n",
    "    train_dataset = EarthDataSet(dict_train)\n",
    "    valid_dataset = EarthDataSet(dict_valid)\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthDataSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['sst'])\n",
    "\n",
    "    def __getitem__(self, idx):   \n",
    "        return (self.data['sst'][idx], self.data['t300'][idx], self.data['ua'][idx], self.data['va'][idx]), self.data['label'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coreff(x, y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    c1 = sum((x - x_mean) * (y - y_mean))\n",
    "    c2 = sum((x - x_mean)**2) * sum((y - y_mean)**2)\n",
    "    return c1/np.sqrt(c2)\n",
    "\n",
    "def rmse(preds, y):\n",
    "    r = np.sqrt(sum((preds - y)**2) / preds.shape[0])\n",
    "    return r\n",
    "\n",
    "def eval_score(preds, label):\n",
    "    acskill_socre = 0\n",
    "    rmse_score = 0\n",
    "    a = [1.5]*4 + [2]*7 + [3]*7 + [4]*6\n",
    "    for i in range(24):\n",
    "        r = rmse(preds[:, i], label[:, i], ) # T时刻 (100,)\n",
    "        cor = coreff(preds[:, i], label[:, i], )\n",
    "    \n",
    "        rmse_score += r\n",
    "        acskill_socre += a[i] * np.log(i+1) * cor\n",
    "    print(\"acskill_socre:{}, rmse_score:{}\".format(2/3*acskill_socre, rmse_score))\n",
    "    return 2/3 * acskill_socre - rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    best_score = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        all_loss = []\n",
    "        for step, ((sst, t300, ua, va), label) in enumerate(train_loader):                \n",
    "            sst = sst.to(device).float()\n",
    "            t300 = t300.to(device).float()\n",
    "            ua = ua.to(device).float()\n",
    "            va = va.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            label = label.to(device).float()\n",
    "            preds = model(sst, t300, ua, va)\n",
    "            loss = loss_fn(preds, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            all_loss.append(loss.item())\n",
    "            if step%20 == 0:\n",
    "                print('Step: {}, Train Loss: {}'.format(step, loss))\n",
    "        print('Epoch: {}, Train loss: {}'.format(epoch+1, np.mean(all_loss)))\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for step, ((sst, t300, ua, va), label) in enumerate(valid_loader):\n",
    "            sst = sst.to(device).float()\n",
    "            t300 = t300.to(device).float()\n",
    "            ua = ua.to(device).float()\n",
    "            va = va.to(device).float()\n",
    "            label = label.to(device).float()\n",
    "            preds = model(sst, t300, ua, va)\n",
    "\n",
    "            y_pred.append(preds)\n",
    "            y_true.append(label)\n",
    "\n",
    "        y_true = torch.cat(y_true, axis=0)\n",
    "        y_pred = torch.cat(y_pred, axis=0)\n",
    "        score = eval_score(y_true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "        print('Epoch: {}, Valid Score: {}'.format(epoch+1,score))\n",
    "\n",
    "        torch.save(model.state_dict(), './models/basemodel_epoch_{}.pt'.format(epoch))\n",
    "        if score > best_score:\n",
    "            torch.save(model.state_dict(), './models/basemodel_best.pt')\n",
    "            print('Model saved successfully')\n",
    "            best_score = score\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4645, Valid samples: 100\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "train_dataset, valid_dataset = load_data()      \n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleSpatailTimeNN(nn.Module):\n",
    "    def __init__(self, embed_dim=128):\n",
    "        super(simpleSpatailTimeNN, self).__init__()\n",
    "        resnet = models.resnet18()\n",
    "        resnet.conv1 = nn.Conv2d(4, 64, kernel_size=(3, 3), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        resnet.fc = nn.Linear(resnet.fc.in_features, embed_dim)\n",
    "        self.resnet = resnet\n",
    "        self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = embed_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, embed_dim*2))\n",
    "        self.linear = nn.Linear(embed_dim*2, 24)\n",
    "\n",
    "    def forward(self, sst, t300, ua, va):\n",
    "        x = torch.cat([sst.unsqueeze(2), t300.unsqueeze(2), ua.unsqueeze(2), va.unsqueeze(2)], dim=2) # b * 12 * 4 * 24 * 72\n",
    "        seq = []\n",
    "        for t in range(x.shape[1]):\n",
    "            t_input = x[:,t,:,:,:] # b * 4 * 24 * 72\n",
    "            t_output = self.resnet(t_input) #  # b * 24\n",
    "            seq.append(t_output)\n",
    "        x = torch.stack(seq).transpose(0,1) # b * 12 * 128\n",
    "        x, _ = self.lstm(x) # b * 12 * 64\n",
    "        x = self.avgpool(x).squeeze(-2) # b * 24\n",
    "        x = self.linear(x)  # b * 24\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simpleSpatailTimeNN()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=8e-5)\n",
    "loss_fn = nn.MSELoss()   \n",
    "\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simpleSpatailTimeNN(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
       "  )\n",
       "  (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 256))\n",
       "  (linear): Linear(in_features=256, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Train Loss: 1.3714359998703003\n",
      "Step: 20, Train Loss: 0.5309656262397766\n",
      "Step: 40, Train Loss: 0.9029960632324219\n",
      "Step: 60, Train Loss: 0.9365097880363464\n",
      "Step: 80, Train Loss: 0.3273836672306061\n",
      "Step: 100, Train Loss: 0.21815073490142822\n",
      "Step: 120, Train Loss: 0.3888990581035614\n",
      "Step: 140, Train Loss: 0.48440560698509216\n",
      "Epoch: 1, Train loss: 0.6371628948270458\n",
      "acskill_socre:15.662441652257712, rmse_score:18.703890031100656\n",
      "Epoch: 1, Valid Score: -3.0414483788429436\n",
      "\n",
      "Step: 0, Train Loss: 1.319894552230835\n",
      "Step: 20, Train Loss: 0.4471575617790222\n",
      "Step: 40, Train Loss: 0.676895260810852\n",
      "Step: 60, Train Loss: 0.9548603892326355\n",
      "Step: 80, Train Loss: 0.30657172203063965\n",
      "Step: 100, Train Loss: 0.20888444781303406\n",
      "Step: 120, Train Loss: 0.3765636384487152\n",
      "Step: 140, Train Loss: 0.43849778175354004\n",
      "Epoch: 2, Train loss: 0.5570397427024907\n",
      "acskill_socre:9.656904772380539, rmse_score:18.64276212419634\n",
      "Epoch: 2, Valid Score: -8.985857351815802\n",
      "\n",
      "Step: 0, Train Loss: 1.3049683570861816\n",
      "Step: 20, Train Loss: 0.38939499855041504\n",
      "Step: 40, Train Loss: 0.5151602029800415\n",
      "Step: 60, Train Loss: 0.8763761520385742\n",
      "Step: 80, Train Loss: 0.2736305296421051\n",
      "Step: 100, Train Loss: 0.22541402280330658\n",
      "Step: 120, Train Loss: 0.3035082519054413\n",
      "Step: 140, Train Loss: 0.36956411600112915\n",
      "Epoch: 3, Train loss: 0.49358654787687406\n",
      "acskill_socre:3.6162093615904816, rmse_score:19.922689636798555\n",
      "Epoch: 3, Valid Score: -16.306480275208074\n",
      "\n",
      "Step: 0, Train Loss: 1.1741185188293457\n",
      "Step: 20, Train Loss: 0.3004356324672699\n",
      "Step: 40, Train Loss: 0.38685572147369385\n",
      "Step: 60, Train Loss: 0.7209681272506714\n",
      "Step: 80, Train Loss: 0.23581364750862122\n",
      "Step: 100, Train Loss: 0.20508155226707458\n",
      "Step: 120, Train Loss: 0.21980392932891846\n",
      "Step: 140, Train Loss: 0.29744869470596313\n",
      "Epoch: 4, Train loss: 0.3948369159375968\n",
      "acskill_socre:-0.2727549612915394, rmse_score:21.21880158424719\n",
      "Epoch: 4, Valid Score: -21.491556545538728\n",
      "\n",
      "Step: 0, Train Loss: 1.010185718536377\n",
      "Step: 20, Train Loss: 0.2548972964286804\n",
      "Step: 40, Train Loss: 0.31057390570640564\n",
      "Step: 60, Train Loss: 0.5736783742904663\n",
      "Step: 80, Train Loss: 0.19618837535381317\n",
      "Step: 100, Train Loss: 0.14571703970432281\n",
      "Step: 120, Train Loss: 0.20860162377357483\n",
      "Step: 140, Train Loss: 0.22831062972545624\n",
      "Epoch: 5, Train loss: 0.321599256655533\n",
      "acskill_socre:-0.13151478042703763, rmse_score:21.440307537029057\n",
      "Epoch: 5, Valid Score: -21.571822317456093\n",
      "\n",
      "Step: 0, Train Loss: 0.8214085102081299\n",
      "Step: 20, Train Loss: 0.22527222335338593\n",
      "Step: 40, Train Loss: 0.2466086447238922\n",
      "Step: 60, Train Loss: 0.48458331823349\n",
      "Step: 80, Train Loss: 0.19730180501937866\n",
      "Step: 100, Train Loss: 0.19127468764781952\n",
      "Step: 120, Train Loss: 0.19143158197402954\n",
      "Step: 140, Train Loss: 0.17792028188705444\n",
      "Epoch: 6, Train loss: 0.27341630881371565\n",
      "acskill_socre:-5.29043253714132, rmse_score:22.52354423467459\n",
      "Epoch: 6, Valid Score: -27.81397677181591\n",
      "\n",
      "Step: 0, Train Loss: 0.5982707738876343\n",
      "Step: 20, Train Loss: 0.2232273519039154\n",
      "Step: 40, Train Loss: 0.1897003948688507\n",
      "Step: 60, Train Loss: 0.3725878596305847\n",
      "Step: 80, Train Loss: 0.19255714118480682\n",
      "Step: 100, Train Loss: 0.16965556144714355\n",
      "Step: 120, Train Loss: 0.18936124444007874\n",
      "Step: 140, Train Loss: 0.13246428966522217\n",
      "Epoch: 7, Train loss: 0.23387765807852354\n",
      "acskill_socre:0.31792190973019163, rmse_score:21.389195866137772\n",
      "Epoch: 7, Valid Score: -21.07127395640758\n",
      "\n",
      "Step: 0, Train Loss: 0.4553334712982178\n",
      "Step: 20, Train Loss: 0.1560511589050293\n",
      "Step: 40, Train Loss: 0.1616026610136032\n",
      "Step: 60, Train Loss: 0.3119989037513733\n",
      "Step: 80, Train Loss: 0.13817735016345978\n",
      "Step: 100, Train Loss: 0.1301957219839096\n",
      "Step: 120, Train Loss: 0.14479604363441467\n",
      "Step: 140, Train Loss: 0.10400038957595825\n",
      "Epoch: 8, Train loss: 0.19496047450867418\n",
      "acskill_socre:1.6548759156641286, rmse_score:22.685270061289494\n",
      "Epoch: 8, Valid Score: -21.030394145625365\n",
      "\n",
      "Step: 0, Train Loss: 0.4239509105682373\n",
      "Step: 20, Train Loss: 0.12733978033065796\n",
      "Step: 40, Train Loss: 0.2001170814037323\n",
      "Step: 60, Train Loss: 0.24355630576610565\n",
      "Step: 80, Train Loss: 0.09201602637767792\n",
      "Step: 100, Train Loss: 0.12422715127468109\n",
      "Step: 120, Train Loss: 0.14102376997470856\n",
      "Step: 140, Train Loss: 0.07475936412811279\n",
      "Epoch: 9, Train loss: 0.16957525840054635\n",
      "acskill_socre:0.7948933162539321, rmse_score:21.533410415582967\n",
      "Epoch: 9, Valid Score: -20.738517099329034\n",
      "\n",
      "Step: 0, Train Loss: 0.33870935440063477\n",
      "Step: 20, Train Loss: 0.09251396358013153\n",
      "Step: 40, Train Loss: 0.171995609998703\n",
      "Step: 60, Train Loss: 0.17972759902477264\n",
      "Step: 80, Train Loss: 0.1224197968840599\n",
      "Step: 100, Train Loss: 0.07951943576335907\n",
      "Step: 120, Train Loss: 0.11764131486415863\n",
      "Step: 140, Train Loss: 0.10141019523143768\n",
      "Epoch: 10, Train loss: 0.14232077786367234\n",
      "acskill_socre:7.896587999949196, rmse_score:20.542778472789678\n",
      "Epoch: 10, Valid Score: -12.646190472840482\n",
      "\n",
      "Step: 0, Train Loss: 0.3481239974498749\n",
      "Step: 20, Train Loss: 0.07134965062141418\n",
      "Step: 40, Train Loss: 0.08870047330856323\n",
      "Step: 60, Train Loss: 0.15316013991832733\n",
      "Step: 80, Train Loss: 0.10060161352157593\n",
      "Step: 100, Train Loss: 0.05999326333403587\n",
      "Step: 120, Train Loss: 0.09423267841339111\n",
      "Step: 140, Train Loss: 0.09812183678150177\n",
      "Epoch: 11, Train loss: 0.12257591145087594\n",
      "acskill_socre:6.76627042442189, rmse_score:21.099785938715105\n",
      "Epoch: 11, Valid Score: -14.333515514293214\n",
      "\n",
      "Step: 0, Train Loss: 0.29723137617111206\n",
      "Step: 20, Train Loss: 0.0692448616027832\n",
      "Step: 40, Train Loss: 0.08013610541820526\n",
      "Step: 60, Train Loss: 0.14178737998008728\n",
      "Step: 80, Train Loss: 0.08076202869415283\n",
      "Step: 100, Train Loss: 0.05254976451396942\n",
      "Step: 120, Train Loss: 0.10433930158615112\n",
      "Step: 140, Train Loss: 0.056201037019491196\n",
      "Epoch: 12, Train loss: 0.10828995709754016\n",
      "acskill_socre:4.710182021602776, rmse_score:21.874264727590234\n",
      "Epoch: 12, Valid Score: -17.164082705987457\n",
      "\n",
      "Step: 0, Train Loss: 0.21236714720726013\n",
      "Step: 20, Train Loss: 0.06189063936471939\n",
      "Step: 40, Train Loss: 0.0967848151922226\n",
      "Step: 60, Train Loss: 0.08711715042591095\n",
      "Step: 80, Train Loss: 0.07090594619512558\n",
      "Step: 100, Train Loss: 0.06452161073684692\n",
      "Step: 120, Train Loss: 0.09100715816020966\n",
      "Step: 140, Train Loss: 0.059834741055965424\n",
      "Epoch: 13, Train loss: 0.09505923533786649\n",
      "acskill_socre:8.703036050719321, rmse_score:21.85272116980299\n",
      "Epoch: 13, Valid Score: -13.149685119083669\n",
      "\n",
      "Step: 0, Train Loss: 0.1811811774969101\n",
      "Step: 20, Train Loss: 0.047278761863708496\n",
      "Step: 40, Train Loss: 0.073707714676857\n",
      "Step: 60, Train Loss: 0.08073117583990097\n",
      "Step: 80, Train Loss: 0.05649047717452049\n",
      "Step: 100, Train Loss: 0.0709291398525238\n",
      "Step: 120, Train Loss: 0.08579867333173752\n",
      "Step: 140, Train Loss: 0.04914169758558273\n",
      "Epoch: 14, Train loss: 0.0842678221070195\n",
      "acskill_socre:6.9514486502212645, rmse_score:21.45329821960786\n",
      "Epoch: 14, Valid Score: -14.501849569386595\n",
      "\n",
      "Step: 0, Train Loss: 0.16706745326519012\n",
      "Step: 20, Train Loss: 0.056583017110824585\n",
      "Step: 40, Train Loss: 0.10303302109241486\n",
      "Step: 60, Train Loss: 0.08655105531215668\n",
      "Step: 80, Train Loss: 0.04644715040922165\n",
      "Step: 100, Train Loss: 0.05143088102340698\n",
      "Step: 120, Train Loss: 0.08991818130016327\n",
      "Step: 140, Train Loss: 0.05981893464922905\n",
      "Epoch: 15, Train loss: 0.08106607497248748\n",
      "acskill_socre:5.711678471692708, rmse_score:21.552851623932295\n",
      "Epoch: 15, Valid Score: -15.841173152239588\n",
      "\n",
      "Step: 0, Train Loss: 0.18213912844657898\n",
      "Step: 20, Train Loss: 0.05273197591304779\n",
      "Step: 40, Train Loss: 0.07072567939758301\n",
      "Step: 60, Train Loss: 0.07093234360218048\n",
      "Step: 80, Train Loss: 0.05223003774881363\n",
      "Step: 100, Train Loss: 0.03676240146160126\n",
      "Step: 120, Train Loss: 0.07553013414144516\n",
      "Step: 140, Train Loss: 0.04630918800830841\n",
      "Epoch: 16, Train loss: 0.0781968711071635\n",
      "acskill_socre:1.8254338330667657, rmse_score:22.904210586362808\n",
      "Epoch: 16, Valid Score: -21.078776753296044\n",
      "\n",
      "Step: 0, Train Loss: 0.1665060967206955\n",
      "Step: 20, Train Loss: 0.05707147717475891\n",
      "Step: 40, Train Loss: 0.057278916239738464\n",
      "Step: 60, Train Loss: 0.0836557000875473\n",
      "Step: 80, Train Loss: 0.05515844374895096\n",
      "Step: 100, Train Loss: 0.041959598660469055\n",
      "Step: 120, Train Loss: 0.06484096497297287\n",
      "Step: 140, Train Loss: 0.04610392451286316\n",
      "Epoch: 17, Train loss: 0.07805187122462547\n",
      "acskill_socre:-1.6373238712336795, rmse_score:22.165397416110427\n",
      "Epoch: 17, Valid Score: -23.802721287344106\n",
      "\n",
      "Step: 0, Train Loss: 0.10857948660850525\n",
      "Step: 20, Train Loss: 0.06971543282270432\n",
      "Step: 40, Train Loss: 0.06302975118160248\n",
      "Step: 60, Train Loss: 0.07565440237522125\n",
      "Step: 80, Train Loss: 0.05972735211253166\n",
      "Step: 100, Train Loss: 0.04816756770014763\n",
      "Step: 120, Train Loss: 0.05754895135760307\n",
      "Step: 140, Train Loss: 0.05130743607878685\n",
      "Epoch: 18, Train loss: 0.07256471003367476\n",
      "acskill_socre:-0.4864988070478245, rmse_score:22.377903097247263\n",
      "Epoch: 18, Valid Score: -22.864401904295086\n",
      "\n",
      "Step: 0, Train Loss: 0.08606688678264618\n",
      "Step: 20, Train Loss: 0.05457044765353203\n",
      "Step: 40, Train Loss: 0.07959185540676117\n",
      "Step: 60, Train Loss: 0.06838589906692505\n",
      "Step: 80, Train Loss: 0.05327262729406357\n",
      "Step: 100, Train Loss: 0.03676971048116684\n",
      "Step: 120, Train Loss: 0.05307478457689285\n",
      "Step: 140, Train Loss: 0.03596397489309311\n",
      "Epoch: 19, Train loss: 0.06874530328667328\n",
      "acskill_socre:2.0130539124710936, rmse_score:21.488788043075857\n",
      "Epoch: 19, Valid Score: -19.475734130604764\n",
      "\n",
      "Step: 0, Train Loss: 0.11283814162015915\n",
      "Step: 20, Train Loss: 0.050375401973724365\n",
      "Step: 40, Train Loss: 0.08104263991117477\n",
      "Step: 60, Train Loss: 0.06621851027011871\n",
      "Step: 80, Train Loss: 0.04250660538673401\n",
      "Step: 100, Train Loss: 0.031309157609939575\n",
      "Step: 120, Train Loss: 0.047745928168296814\n",
      "Step: 140, Train Loss: 0.0361456423997879\n",
      "Epoch: 20, Train loss: 0.06556532910884652\n",
      "acskill_socre:1.7113378318175054, rmse_score:23.0826487823266\n",
      "Epoch: 20, Valid Score: -21.371310950509095\n",
      "\n",
      "Step: 0, Train Loss: 0.08921723067760468\n",
      "Step: 20, Train Loss: 0.04728732630610466\n",
      "Step: 40, Train Loss: 0.05884119123220444\n",
      "Step: 60, Train Loss: 0.07947185635566711\n",
      "Step: 80, Train Loss: 0.03540297597646713\n",
      "Step: 100, Train Loss: 0.03395296633243561\n",
      "Step: 120, Train Loss: 0.048160798847675323\n",
      "Step: 140, Train Loss: 0.03712090849876404\n",
      "Epoch: 21, Train loss: 0.06337129558143142\n",
      "acskill_socre:-0.30537697993407403, rmse_score:22.14865374686637\n",
      "Epoch: 21, Valid Score: -22.454030726800443\n",
      "\n",
      "Step: 0, Train Loss: 0.0784468874335289\n",
      "Step: 20, Train Loss: 0.04664778709411621\n",
      "Step: 40, Train Loss: 0.0615120604634285\n",
      "Step: 60, Train Loss: 0.06626462936401367\n",
      "Step: 80, Train Loss: 0.03803761303424835\n",
      "Step: 100, Train Loss: 0.030332326889038086\n",
      "Step: 120, Train Loss: 0.05192005634307861\n",
      "Step: 140, Train Loss: 0.033479224890470505\n",
      "Epoch: 22, Train loss: 0.06317869063517818\n",
      "acskill_socre:-0.2981889719894025, rmse_score:21.55961811015446\n",
      "Epoch: 22, Valid Score: -21.857807082143864\n",
      "\n",
      "Step: 0, Train Loss: 0.08282860368490219\n",
      "Step: 20, Train Loss: 0.0514063835144043\n",
      "Step: 40, Train Loss: 0.056886982172727585\n",
      "Step: 60, Train Loss: 0.07142824679613113\n",
      "Step: 80, Train Loss: 0.050413768738508224\n",
      "Step: 100, Train Loss: 0.031883083283901215\n",
      "Step: 120, Train Loss: 0.04250123351812363\n",
      "Step: 140, Train Loss: 0.03404269739985466\n",
      "Epoch: 23, Train loss: 0.06337987861200554\n",
      "acskill_socre:0.34662362393982005, rmse_score:21.450588047717318\n",
      "Epoch: 23, Valid Score: -21.103964423777498\n",
      "\n",
      "Step: 0, Train Loss: 0.07695837318897247\n",
      "Step: 20, Train Loss: 0.04960261285305023\n",
      "Step: 40, Train Loss: 0.056543078273534775\n",
      "Step: 60, Train Loss: 0.07240273803472519\n",
      "Step: 80, Train Loss: 0.06865188479423523\n",
      "Step: 100, Train Loss: 0.03515397012233734\n",
      "Step: 120, Train Loss: 0.048378001898527145\n",
      "Step: 140, Train Loss: 0.04572771489620209\n",
      "Epoch: 24, Train loss: 0.062385085281239795\n",
      "acskill_socre:7.3150588854500835, rmse_score:21.27443225301439\n",
      "Epoch: 24, Valid Score: -13.959373367564305\n",
      "\n",
      "Step: 0, Train Loss: 0.0712500661611557\n",
      "Step: 20, Train Loss: 0.04624171555042267\n",
      "Step: 40, Train Loss: 0.05689788982272148\n",
      "Step: 60, Train Loss: 0.07047930359840393\n",
      "Step: 80, Train Loss: 0.05686288699507713\n",
      "Step: 100, Train Loss: 0.05073382705450058\n",
      "Step: 120, Train Loss: 0.06202816590666771\n",
      "Step: 140, Train Loss: 0.035977959632873535\n",
      "Epoch: 25, Train loss: 0.06163583471350474\n",
      "acskill_socre:9.661412649838612, rmse_score:21.62183082715299\n",
      "Epoch: 25, Valid Score: -11.960418177314379\n",
      "\n",
      "Step: 0, Train Loss: 0.07813450694084167\n",
      "Step: 20, Train Loss: 0.0474420040845871\n",
      "Step: 40, Train Loss: 0.053839392960071564\n",
      "Step: 60, Train Loss: 0.070169597864151\n",
      "Step: 80, Train Loss: 0.0623394176363945\n",
      "Step: 100, Train Loss: 0.05297201871871948\n",
      "Step: 120, Train Loss: 0.035100482404232025\n",
      "Step: 140, Train Loss: 0.03882397338747978\n",
      "Epoch: 26, Train loss: 0.06009509809927581\n",
      "acskill_socre:6.788036004779976, rmse_score:21.162480084117455\n",
      "Epoch: 26, Valid Score: -14.37444407933748\n",
      "\n",
      "Step: 0, Train Loss: 0.07032801955938339\n",
      "Step: 20, Train Loss: 0.0439579002559185\n",
      "Step: 40, Train Loss: 0.06146015226840973\n",
      "Step: 60, Train Loss: 0.06135660037398338\n",
      "Step: 80, Train Loss: 0.048639796674251556\n",
      "Step: 100, Train Loss: 0.029292233288288116\n",
      "Step: 120, Train Loss: 0.04124131426215172\n",
      "Step: 140, Train Loss: 0.033821623772382736\n",
      "Epoch: 27, Train loss: 0.05593330984654492\n",
      "acskill_socre:1.0012464062872604, rmse_score:21.400670484339006\n",
      "Epoch: 27, Valid Score: -20.399424078051744\n",
      "\n",
      "Step: 0, Train Loss: 0.07733460515737534\n",
      "Step: 20, Train Loss: 0.03774821758270264\n",
      "Step: 40, Train Loss: 0.04406639561057091\n",
      "Step: 60, Train Loss: 0.052115779370069504\n",
      "Step: 80, Train Loss: 0.03373410552740097\n",
      "Step: 100, Train Loss: 0.03152914717793465\n",
      "Step: 120, Train Loss: 0.03928046673536301\n",
      "Step: 140, Train Loss: 0.031242892146110535\n",
      "Epoch: 28, Train loss: 0.052182692154119276\n",
      "acskill_socre:-0.09313986190746895, rmse_score:21.06123172808097\n",
      "Epoch: 28, Valid Score: -21.15437158998844\n",
      "\n",
      "Step: 0, Train Loss: 0.07380101829767227\n",
      "Step: 20, Train Loss: 0.040270984172821045\n",
      "Step: 40, Train Loss: 0.051934000104665756\n",
      "Step: 60, Train Loss: 0.05577629804611206\n",
      "Step: 80, Train Loss: 0.04112733155488968\n",
      "Step: 100, Train Loss: 0.02727575972676277\n",
      "Step: 120, Train Loss: 0.04147353023290634\n",
      "Step: 140, Train Loss: 0.039032574743032455\n",
      "Epoch: 29, Train loss: 0.05068337076585995\n",
      "acskill_socre:5.633288493410518, rmse_score:20.631452783448843\n",
      "Epoch: 29, Valid Score: -14.998164290038325\n",
      "\n",
      "Step: 0, Train Loss: 0.05494825169444084\n",
      "Step: 20, Train Loss: 0.039257995784282684\n",
      "Step: 40, Train Loss: 0.04398420453071594\n",
      "Step: 60, Train Loss: 0.057831645011901855\n",
      "Step: 80, Train Loss: 0.04602165147662163\n",
      "Step: 100, Train Loss: 0.03299376741051674\n",
      "Step: 120, Train Loss: 0.037516847252845764\n",
      "Step: 140, Train Loss: 0.040682997554540634\n",
      "Epoch: 30, Train loss: 0.04937076307067724\n",
      "acskill_socre:9.084915543610954, rmse_score:21.003311094083664\n",
      "Epoch: 30, Valid Score: -11.91839555047271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/basemodel_epoch_5.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './tcdata/enso_round1_test_20210201/'\n",
    "\n",
    "### load test data\n",
    "files = os.listdir(test_path)\n",
    "test_feas_dict = {}\n",
    "for file in files:\n",
    "    test_feas_dict[file] = np.load(test_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. predict\n",
    "test_predicts_dict = {}\n",
    "for file_name,val in test_feas_dict.items():\n",
    "    SST = torch.tensor(val[:,:,:,0]).unsqueeze(0).to(device).float()\n",
    "    T300 = torch.tensor(val[:,:,:,1]).unsqueeze(0).to(device).float()\n",
    "    Ua = torch.tensor(val[:,:,:,2]).unsqueeze(0).to(device).float()\n",
    "    Va = torch.tensor(val[:,:,:,3]).unsqueeze(0).to(device).float()\n",
    "    test_predicts_dict[file_name] = model(SST, T300, Ua, Va).view(-1).detach().cpu().numpy()\n",
    "#     test_predicts_dict[file_name] = model.predict(val.reshape([-1,12])[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. save results\n",
    "if os.path.exists('./result/'):  \n",
    "    shutil.rmtree('./result/', ignore_errors=True)  \n",
    "os.makedirs('./result/')\n",
    "for file_name, val in test_predicts_dict.items(): \n",
    "    np.save('./result/' + file_name, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_zip(res_dir='./result', output_dir='result.zip'):  \n",
    "    z = zipfile.ZipFile(output_dir, 'w')  \n",
    "    for file in os.listdir(res_dir):  \n",
    "        if '.npy' not in file:\n",
    "            continue\n",
    "        z.write(res_dir + os.sep + file)  \n",
    "    z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./result/test_0144-01-12.npy\n"
     ]
    }
   ],
   "source": [
    "make_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
